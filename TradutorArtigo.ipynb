{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71bb2df0-3d65-43f6-b932-18c3451e87b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\pedro neto\\anaconda3\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\pedro neto\\anaconda3\\lib\\site-packages (4.12.3)\n",
      "Collecting openai\n",
      "  Using cached openai-2.15.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting langchain-openai\n",
      "  Using cached langchain_openai-1.1.7-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pedro neto\\anaconda3\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pedro neto\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pedro neto\\anaconda3\\lib\\site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pedro neto\\anaconda3\\lib\\site-packages (from requests) (2025.8.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\pedro neto\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\pedro neto\\anaconda3\\lib\\site-packages (from openai) (4.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\pedro neto\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\pedro neto\\anaconda3\\lib\\site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.10.0 (from openai)\n",
      "  Downloading jiter-0.12.0-cp313-cp313-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\pedro neto\\anaconda3\\lib\\site-packages (from openai) (2.10.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\pedro neto\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\pedro neto\\anaconda3\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\pedro neto\\anaconda3\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\pedro neto\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\pedro neto\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\pedro neto\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\pedro neto\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
      "Collecting langchain-core<2.0.0,>=1.2.6 (from langchain-openai)\n",
      "  Using cached langchain_core-1.2.7-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting tiktoken<1.0.0,>=0.7.0 (from langchain-openai)\n",
      "  Downloading tiktoken-0.12.0-cp313-cp313-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\pedro neto\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (1.33)\n",
      "Collecting langsmith<1.0.0,>=0.3.45 (from langchain-core<2.0.0,>=1.2.6->langchain-openai)\n",
      "  Using cached langsmith-0.6.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\pedro neto\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (24.2)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\pedro neto\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\pedro neto\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (9.0.0)\n",
      "Collecting uuid-utils<1.0,>=0.12.0 (from langchain-core<2.0.0,>=1.2.6->langchain-openai)\n",
      "  Using cached uuid_utils-0.13.0-cp39-abi3-win_amd64.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\pedro neto\\anaconda3\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.6->langchain-openai) (2.1)\n",
      "Collecting orjson>=3.9.14 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai)\n",
      "  Downloading orjson-3.11.5-cp313-cp313-win_amd64.whl.metadata (42 kB)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\pedro neto\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\pedro neto\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.23.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\pedro neto\\anaconda3\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\pedro neto\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Using cached openai-2.15.0-py3-none-any.whl (1.1 MB)\n",
      "Downloading jiter-0.12.0-cp313-cp313-win_amd64.whl (204 kB)\n",
      "Using cached langchain_openai-1.1.7-py3-none-any.whl (84 kB)\n",
      "Using cached langchain_core-1.2.7-py3-none-any.whl (490 kB)\n",
      "Using cached langsmith-0.6.2-py3-none-any.whl (282 kB)\n",
      "Downloading tiktoken-0.12.0-cp313-cp313-win_amd64.whl (879 kB)\n",
      "   ---------------------------------------- 0.0/879.1 kB ? eta -:--:--\n",
      "   ----------------------------------- ---- 786.4/879.1 kB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 879.1/879.1 kB 4.4 MB/s eta 0:00:00\n",
      "Using cached uuid_utils-0.13.0-cp39-abi3-win_amd64.whl (183 kB)\n",
      "Downloading orjson-3.11.5-cp313-cp313-win_amd64.whl (133 kB)\n",
      "Installing collected packages: uuid-utils, orjson, jiter, tiktoken, openai, langsmith, langchain-core, langchain-openai\n",
      "\n",
      "   ----- ---------------------------------- 1/8 [orjson]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   -------------------- ------------------- 4/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [langsmith]\n",
      "   ------------------------- -------------- 5/8 [langsmith]\n",
      "   ------------------------- -------------- 5/8 [langsmith]\n",
      "   ------------------------- -------------- 5/8 [langsmith]\n",
      "   ------------------------- -------------- 5/8 [langsmith]\n",
      "   ------------------------- -------------- 5/8 [langsmith]\n",
      "   ------------------------- -------------- 5/8 [langsmith]\n",
      "   ------------------------- -------------- 5/8 [langsmith]\n",
      "   ------------------------- -------------- 5/8 [langsmith]\n",
      "   ------------------------------ --------- 6/8 [langchain-core]\n",
      "   ------------------------------ --------- 6/8 [langchain-core]\n",
      "   ------------------------------ --------- 6/8 [langchain-core]\n",
      "   ------------------------------ --------- 6/8 [langchain-core]\n",
      "   ------------------------------ --------- 6/8 [langchain-core]\n",
      "   ------------------------------ --------- 6/8 [langchain-core]\n",
      "   ------------------------------ --------- 6/8 [langchain-core]\n",
      "   ------------------------------ --------- 6/8 [langchain-core]\n",
      "   ------------------------------ --------- 6/8 [langchain-core]\n",
      "   ------------------------------ --------- 6/8 [langchain-core]\n",
      "   ------------------------------ --------- 6/8 [langchain-core]\n",
      "   ------------------------------ --------- 6/8 [langchain-core]\n",
      "   ------------------------------ --------- 6/8 [langchain-core]\n",
      "   ------------------------------ --------- 6/8 [langchain-core]\n",
      "   ------------------------------ --------- 6/8 [langchain-core]\n",
      "   ------------------------------ --------- 6/8 [langchain-core]\n",
      "   ------------------------------ --------- 6/8 [langchain-core]\n",
      "   ------------------------------ --------- 6/8 [langchain-core]\n",
      "   ------------------------------ --------- 6/8 [langchain-core]\n",
      "   ------------------------------ --------- 6/8 [langchain-core]\n",
      "   ------------------------------ --------- 6/8 [langchain-core]\n",
      "   ------------------------------ --------- 6/8 [langchain-core]\n",
      "   ----------------------------------- ---- 7/8 [langchain-openai]\n",
      "   ----------------------------------- ---- 7/8 [langchain-openai]\n",
      "   ---------------------------------------- 8/8 [langchain-openai]\n",
      "\n",
      "Successfully installed jiter-0.12.0 langchain-core-1.2.7 langchain-openai-1.1.7 langsmith-0.6.2 openai-2.15.0 orjson-3.11.5 tiktoken-0.12.0 uuid-utils-0.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4 openai langchain-openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271d3dde-ebbc-41d4-bdcc-2ccb9e73f0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_text_from_url(url):\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "      soup = BeautifulSoup(response.text, 'html.parser')\n",
    "      for script_or_style in soup([\"script\", \"style\"]):\n",
    "        script_or_style.decompose()\n",
    "      text = soup.get_text(separator= ' ')\n",
    "#limpar texto\n",
    "      lines = (line.strip() for line in text.splitlines())\n",
    "      chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "      texto_limpo = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "      return texto_limpo\n",
    "\n",
    "    else:\n",
    "      print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\n",
    "      return None\n",
    "\n",
    "    text = soup.get_text()\n",
    "    return text\n",
    "extract_text_from_url('https://dev.to/alextheluchador/how-i-passed-the-azure-ai-102-exam-4gg7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c3f006-7758-43ca-a3bc-70e04f6b9622",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models.azure import AzureChatOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureChatOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AZURE_ENDPOINT\"),\n",
    "    azure_api_key=os.getenv(\"AZURE_API_KEY\"),\n",
    "    openai_api_version=os.getenv(\"OPENAI_API_VERSION\"),\n",
    "    deployment_name=os.getenv(\"DEPLOYMENT_NAME\"),\n",
    "    model=\"gpt-4o\",\n",
    "    max_retries=0\n",
    ")\n",
    "\n",
    "def translate_text(text, target_language=\"Portuguese\"):\n",
    "    prompt = f\"Translate the following text to {target_language}:\\n\\n{text}\"\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that translates text.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8deddc4-f3a2-4ced-97c8-773d482fab5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_text = extract_text_from_url(\"<URL OCULTADA>\")\n",
    "article = translate_text(extracted_text, target_language=\"Portuguese\")\n",
    "\n",
    "print(article)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
